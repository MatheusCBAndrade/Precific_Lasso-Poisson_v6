{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando os arquivos txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho para a pasta que contém os arquivos .xlsx\n",
    "path = r'C:\\Users\\mathe\\OneDrive\\Área de Trabalho\\SoccerIA\\Datasets finais europeus xlsx'\n",
    "\n",
    "# Lista todos os arquivos na pasta\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Filtra a lista de arquivos para incluir apenas os arquivos .xlsx\n",
    "xlsx_files = [f for f in files if f.endswith('.xlsx')]\n",
    "\n",
    "colunas_interesse = [\n",
    "    'team1_goals', 'team2_goals',\n",
    "    'team1_total_shots', 'team2_total_shots', 'team1_shots_on_target',\n",
    "    'team2_shots_on_target', 'team1_fouls', 'team2_fouls', 'team1_corners',\n",
    "    'team2_corners', 'team1_yellow_cards', 'team2_yellow_cards',\n",
    "    'team1_red_cards', 'team2_red_cards', 'team1_shots_out',\n",
    "    'team2_shots_out'\n",
    "]\n",
    "\n",
    "# Carrega cada arquivo .xlsx em um dataframe e armazena na lista dfss\n",
    "for file in xlsx_files:\n",
    "    data_path = os.path.join(path, file)\n",
    "    df = pd.read_excel(data_path)\n",
    "\n",
    "    # Calcula a média para as colunas de interesse\n",
    "    medias = df[colunas_interesse].mean()\n",
    "\n",
    "    # Cria o dicionário\n",
    "    dict_medias = medias.to_dict()\n",
    "\n",
    "    # Salva o dicionário em um arquivo .txt\n",
    "    nome_txt = os.path.splitext(file)[0] + '.txt'  # Substitui a extensão por .txt\n",
    "    caminho_txt = os.path.join(path, nome_txt)\n",
    "    \n",
    "    with open(caminho_txt, 'w') as arquivo_txt:\n",
    "        for key, value in dict_medias.items():\n",
    "            linha = f\"{key}: {value}\\n\"\n",
    "            arquivo_txt.write(linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os arquivos excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alemanha A.xlsx\n",
      "(4896, 21)\n",
      "Alemanha B.xlsx\n",
      "(1530, 21)\n",
      "Belgica A.xlsx\n",
      "(839, 21)\n",
      "Escocia A.xlsx\n",
      "(4065, 21)\n",
      "Espanha A.xlsx\n",
      "(6460, 21)\n",
      "Espanha B.xlsx\n",
      "(2289, 21)\n",
      "França A.xlsx\n",
      "(5596, 21)\n",
      "França B.xlsx\n",
      "(1039, 21)\n",
      "Grecia A.xlsx\n",
      "(720, 21)\n",
      "Holanda A.xlsx\n",
      "(1456, 21)\n",
      "Inglaterra A.xlsx\n",
      "(7418, 21)\n",
      "Inglaterra B.xlsx\n",
      "(9775, 21)\n",
      "Inglaterra C.xlsx\n",
      "(9608, 21)\n",
      "Inglaterra D.xlsx\n",
      "(9710, 21)\n",
      "Italia B.xlsx\n",
      "(1841, 21)\n",
      "Italia_A.xlsx\n",
      "(6680, 21)\n",
      "Portugal A.xlsx\n",
      "(1530, 21)\n",
      "Turquia A.xlsx\n",
      "(1610, 21)\n",
      "(77062, 21)\n",
      "Index(['championship', 'date', 'team1', 'team2', 'team1_goals', 'team2_goals',\n",
      "       'team1_total_shots', 'team2_total_shots', 'team1_shots_on_target',\n",
      "       'team2_shots_on_target', 'team1_fouls', 'team2_fouls', 'team1_corners',\n",
      "       'team2_corners', 'team1_yellow_cards', 'team2_yellow_cards',\n",
      "       'team1_red_cards', 'team2_red_cards', 'team1_shots_out',\n",
      "       'team2_shots_out', 'season'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho para a pasta que contém os arquivos .xlsx\n",
    "path = r'C:\\Users\\mathe\\OneDrive\\Área de Trabalho\\SoccerIA\\Datasets finais europeus xlsx'\n",
    "\n",
    "# Lista todos os arquivos na pasta\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Filtra a lista de arquivos para incluir apenas os arquivos .xlsx\n",
    "xlsx_files = [f for f in files if f.endswith('.xlsx')]\n",
    "\n",
    "dfss = []\n",
    "\n",
    "colunas_interesse = [\n",
    "    'team1_goals', 'team2_goals',\n",
    "    'team1_total_shots', 'team2_total_shots', 'team1_shots_on_target',\n",
    "    'team2_shots_on_target', 'team1_fouls', 'team2_fouls', 'team1_corners',\n",
    "    'team2_corners', 'team1_yellow_cards', 'team2_yellow_cards',\n",
    "    'team1_red_cards', 'team2_red_cards', 'team1_shots_out',\n",
    "    'team2_shots_out'\n",
    "]\n",
    "\n",
    "# Carrega cada arquivo .xlsx em um dataframe e armazena na lista dfss\n",
    "for file in xlsx_files:\n",
    "    data_path = os.path.join(path, file)\n",
    "    df = pd.read_excel(data_path)\n",
    "    \n",
    "    dfss.append(df)\n",
    "    print(file)\n",
    "    print(df.shape)\n",
    "\n",
    "# Combine all the DataFrames into a single DataFrame\n",
    "combined_df_13c = pd.concat(dfss, ignore_index=True)\n",
    "print(combined_df_13c.shape)\n",
    "print(combined_df_13c.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D1' 'D2' 'B1' 'SC0' 'SP1' 'SP2' 'F1' 'F2' 'G1' 'N1' 'E0' 'E1' 'E2' 'E3'\n",
      " 'I2' 'I1' 'P1' 'T1']\n"
     ]
    }
   ],
   "source": [
    "champ_uniques = combined_df_13c['championship'].unique()\n",
    "print(champ_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "(77062, 21)\n"
     ]
    }
   ],
   "source": [
    "nan_counts = combined_df_13c.isna().sum()\n",
    "print(list(nan_counts))\n",
    "print(combined_df_13c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77062, 79)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "combined_df_13c.sort_values('date', inplace=True)\n",
    "\n",
    "\n",
    "combined_df_13c['team1_goals'] = pd.to_numeric(combined_df_13c['team1_goals'], errors='coerce')\n",
    "combined_df_13c['team2_goals'] = pd.to_numeric(combined_df_13c['team2_goals'], errors='coerce')\n",
    "\n",
    "# calculate goal differences\n",
    "combined_df_13c['goal_diff_team1'] = combined_df_13c['team1_goals'] - combined_df_13c['team2_goals']\n",
    "combined_df_13c['goal_diff_team2'] = combined_df_13c['team2_goals'] - combined_df_13c['team1_goals']\n",
    "\n",
    "\n",
    "# calculate big wins and losses\n",
    "combined_df_13c['team1_big_win'] = np.where(combined_df_13c['goal_diff_team1'] >= 2, 1, 0)\n",
    "combined_df_13c['team1_big_loss'] = np.where(combined_df_13c['goal_diff_team1'] <= -2, 1, 0)\n",
    "combined_df_13c['team2_big_win'] = np.where(combined_df_13c['goal_diff_team2'] >= 2, 1, 0)\n",
    "combined_df_13c['team2_big_loss'] = np.where(combined_df_13c['goal_diff_team2'] <= -2, 1, 0)\n",
    "\n",
    "# Initialize big win/loss columns for future matches\n",
    "combined_df_13c['team1_big_wins_last5'] = 0\n",
    "combined_df_13c['team1_big_losses_last5'] = 0\n",
    "combined_df_13c['team2_big_wins_last5'] = 0\n",
    "combined_df_13c['team2_big_losses_last5'] = 0\n",
    "\n",
    "\n",
    "new_cols = ['avg_scr_lasts3_1_home', 'avg_scr_lasts5_1_home', 'avg_scr_lasts3_1_away',\n",
    "            'avg_scr_lasts5_1_away', 'avg_conc_lasts3_1_home', 'avg_conc_lasts5_1_home',\n",
    "            'avg_conc_lasts3_1_away', 'avg_conc_lasts5_1_away', 'avg_scr_lasts3_2_home',\n",
    "            'avg_scr_lasts5_2_home', 'avg_scr_lasts3_2_away', 'avg_scr_lasts5_2_away',\n",
    "            'avg_conc_lasts3_2_home', 'avg_conc_lasts5_2_home', 'avg_conc_lasts3_2_away',\n",
    "            'avg_conc_lasts5_2_away','team1_big_wins_last5', 'team1_big_losses_last5', \n",
    "            'team2_big_wins_last5', 'team2_big_losses_last5',\n",
    "            #abaixo vai ser baseado em finalizações\n",
    "            'avg_total_shots_lasts5_1_home','avg_total_shots_lasts5_1_away','avg_total_shots_lasts5_2_home',\n",
    "            'avg_total_shots_lasts5_2_away', 'avg_otarget_shots_lasts5_1_home','avg_otarget_shots_lasts5_1_away',\n",
    "            'avg_otarget_shots_lasts5_2_home','avg_otarget_shots_lasts5_2_away','avg_out_shots_lasts5_1_home',\n",
    "            'avg_out_shots_lasts5_1_away','avg_out_shots_lasts5_2_home','avg_out_shots_lasts5_2_away',\n",
    "            'avg_conc_total_shots_lasts5_1_home','avg_conc_total_shots_lasts5_1_away',\n",
    "            'avg_conc_total_shots_lasts5_2_home','avg_conc_total_shots_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em corners\n",
    "            'avg_corners_lasts5_1_home','avg_corners_lasts5_1_away', \n",
    "            'avg_corners_conc_lasts5_1_home','avg_corners_conc_lasts5_1_away',\n",
    "            'avg_corners_lasts5_2_home','avg_corners_lasts5_2_away', \n",
    "            'avg_corners_conc_lasts5_2_home', 'avg_corners_conc_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em fouls\n",
    "            'avg_fouls_lasts5_1_home','avg_fouls_lasts5_1_away', \n",
    "            'avg_fouls_conc_lasts5_1_home', 'avg_fouls_conc_lasts5_1_away',\n",
    "            'avg_fouls_lasts5_2_home','avg_fouls_lasts5_2_away', \n",
    "            'avg_fouls_conc_lasts5_2_home', 'avg_fouls_conc_lasts5_2_away'\n",
    "            \n",
    "            ]\n",
    "\n",
    "for col in new_cols:\n",
    "    combined_df_13c[col] = np.nan\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for i, row in combined_df_13c.iterrows():\n",
    "    # For each team, get their past home and away matches before the current date\n",
    "    team1_matches = combined_df_13c[((combined_df_13c['team1'] == row['team1']) | (combined_df_13c['team2'] == row['team1'])) & (combined_df_13c['date'] < row['date']) & (combined_df_13c['season'] == row['season'])].sort_values(by='date')\n",
    "    team2_matches = combined_df_13c[((combined_df_13c['team1'] == row['team2']) | (combined_df_13c['team2'] == row['team2'])) & (combined_df_13c['date'] < row['date']) & (combined_df_13c['season'] == row['season'])].sort_values(by='date')\n",
    "\n",
    "    # For each team, calculate stats for last 5 matches\n",
    "    if not team1_matches.empty:\n",
    "        team1_matches['big_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_win'], team1_matches['team2_big_win'])\n",
    "        team1_matches['big_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_loss'], team1_matches['team2_big_loss'])\n",
    "        combined_df_13c.at[i, 'team1_big_wins_last5'] = team1_matches['big_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_13c.at[i, 'team1_big_losses_last5'] = team1_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "    if not team2_matches.empty:\n",
    "        team2_matches['big_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_win'], team2_matches['team2_big_win'])\n",
    "        team2_matches['big_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_loss'], team2_matches['team2_big_loss'])\n",
    "        combined_df_13c.at[i, 'team2_big_wins_last5'] = team2_matches['big_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_13c.at[i, 'team2_big_losses_last5'] = team2_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "    \n",
    "for i, row in combined_df_13c.iterrows():\n",
    "    team1_home = combined_df_13c[(combined_df_13c['date'] < row['date']) & (combined_df_13c['team1'] == row['team1']) & (combined_df_13c['season'] == row['season'])]\n",
    "    team1_away = combined_df_13c[(combined_df_13c['date'] < row['date']) & (combined_df_13c['team2'] == row['team1']) & (combined_df_13c['season'] == row['season'])]\n",
    "    \n",
    "    team2_home = combined_df_13c[(combined_df_13c['date'] < row['date']) & (combined_df_13c['team1'] == row['team2']) & (combined_df_13c['season'] == row['season'])]\n",
    "    team2_away = combined_df_13c[(combined_df_13c['date'] < row['date']) & (combined_df_13c['team2'] == row['team2']) & (combined_df_13c['season'] == row['season'])]\n",
    "\n",
    "    if not team1_home.empty:\n",
    "        combined_df_13c.at[i, 'avg_scr_lasts3_1_home'] = team1_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_scr_lasts5_1_home'] = team1_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_lasts3_1_home'] = team1_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_lasts5_1_home'] = team1_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_13c.at[i, 'avg_total_shots_lasts5_1_home'] = team1_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_total_shots_lasts5_1_home'] = team1_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_otarget_shots_lasts5_1_home'] = team1_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_out_shots_lasts5_1_home'] = team1_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_out'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_13c.at[i, 'avg_corners_lasts5_1_home'] = team1_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_corners_conc_lasts5_1_home'] = team1_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_13c.at[i, 'avg_fouls_lasts5_1_home'] = team1_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_fouls_conc_lasts5_1_home'] = team1_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team1_away.empty:\n",
    "        combined_df_13c.at[i, 'avg_scr_lasts3_1_away'] = team1_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_scr_lasts5_1_away'] = team1_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_lasts3_1_away'] = team1_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_lasts5_1_away'] = team1_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_13c.at[i, 'avg_total_shots_lasts5_1_away'] = team1_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_otarget_shots_lasts5_1_away'] = team1_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_out_shots_lasts5_1_away'] = team1_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_total_shots_lasts5_1_away'] = team1_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_13c.at[i, 'avg_corners_lasts5_1_away'] = team1_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_corners_conc_lasts5_1_away'] = team1_away['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_13c.at[i, 'avg_fouls_lasts5_1_away'] = team1_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_fouls_conc_lasts5_1_away'] = team1_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team2_home.empty:\n",
    "        combined_df_13c.at[i, 'avg_scr_lasts3_2_home'] = team2_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_scr_lasts5_2_home'] = team2_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_lasts3_2_home'] = team2_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_lasts5_2_home'] = team2_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_13c.at[i, 'avg_total_shots_lasts5_2_home'] = team2_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_otarget_shots_lasts5_2_home'] = team2_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_out_shots_lasts5_2_home'] = team2_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_out'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_total_shots_lasts5_2_home'] = team2_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_13c.at[i, 'avg_corners_lasts5_2_home'] = team2_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_corners_conc_lasts5_2_home'] = team2_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_13c.at[i, 'avg_fouls_lasts5_2_home'] = team2_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_fouls_conc_lasts5_2_home'] = team2_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "\n",
    "    if not team2_away.empty:\n",
    "        combined_df_13c.at[i, 'avg_scr_lasts3_2_away'] = team2_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_scr_lasts5_2_away'] = team2_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_lasts3_2_away'] = team2_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_lasts5_2_away'] = team2_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_13c.at[i, 'avg_total_shots_lasts5_2_away'] = team2_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_otarget_shots_lasts5_2_away'] = team2_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_out_shots_lasts5_2_away'] = team2_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_conc_total_shots_lasts5_2_away'] = team2_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_13c.at[i, 'avg_corners_lasts5_2_away'] = team2_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_corners_conc_lasts5_2_away'] = team2_away['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_13c.at[i, 'avg_fouls_lasts5_2_away'] = team2_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_13c.at[i, 'avg_fouls_conc_lasts5_2_away'] = team2_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_fouls'].isna().any() else np.nan\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_df_13c.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77062, 99)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_result(row):\n",
    "    if row['team1_goals'] > row['team2_goals']:\n",
    "        return pd.Series([3, 0])\n",
    "    elif row['team1_goals'] < row['team2_goals']:\n",
    "        return pd.Series([0, 3])\n",
    "    else:\n",
    "        return pd.Series([1, 1])\n",
    "\n",
    "combined_df_13c[['result_team1', 'result_team2']] = combined_df_13c.apply(get_result, axis=1)\n",
    "\n",
    "def get_streak(df, result_col, results):\n",
    "    result_series = df[result_col].apply(lambda x: 1 if x in results else 0)\n",
    "    result_series = result_series * (result_series.groupby((result_series != result_series.shift()).cumsum()).cumcount() + 1)\n",
    "    return result_series\n",
    "\n",
    "# Create a dictionary to hold individual team dataframes\n",
    "team_df_dict = {}\n",
    "\n",
    "def get_individual_team_df(df, team_name):\n",
    "    if team_name in team_df_dict:\n",
    "        return team_df_dict[team_name]\n",
    "        \n",
    "    team_games = df[(df['team1'] == team_name) | (df['team2'] == team_name)].copy()\n",
    "    team_games['team_is_team1'] = team_games['team1'] == team_name\n",
    "    team_games['team_result'] = np.where(team_games['team_is_team1'], team_games['result_team1'], team_games['result_team2'])\n",
    "    team_games['team_goals'] = np.where(team_games['team_is_team1'], team_games['team1_goals'], team_games['team2_goals'])\n",
    "    team_games['team_redcards'] = np.where(team_games['team_is_team1'], team_games['team1_red_cards'], team_games['team2_red_cards'])\n",
    "\n",
    "    team_games.sort_values('date', inplace=True)\n",
    "    team_games['days_since_last_game'] = team_games['date'].diff().dt.days\n",
    "\n",
    "    team_df_dict[team_name] = team_games\n",
    "    return team_games\n",
    "\n",
    "def get_team_stats(row, df):\n",
    "    team1_games = get_individual_team_df(df, row['team1'])\n",
    "    team2_games = get_individual_team_df(df, row['team2'])\n",
    "\n",
    "    # Filter to include only games that occurred before the current game\n",
    "    team1_games = team1_games[team1_games['date'] < row['date']]\n",
    "    team2_games = team2_games[team2_games['date'] < row['date']]\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    if not team1_games.empty:\n",
    "        stats['team1_winning_streak'] = get_streak(team1_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team1_undefeated_streak'] = get_streak(team1_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team1_losing_streak'] = get_streak(team1_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team1_without_winning_streak'] = get_streak(team1_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_1'] = team1_games.tail(5)['team_result'].mean()\n",
    "        stats['team1_strength'] = team1_games['team_goals'].sum() / (team1_games['team1_goals'].sum() + team1_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_1'] = team1_games['team_result'].sum() / len(team1_games)\n",
    "        rested_4_or_more_days_1 = team1_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_1'] = 1 if rested_4_or_more_days_1 else -1\n",
    "\n",
    "    if not team2_games.empty:\n",
    "        stats['team2_winning_streak'] = get_streak(team2_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team2_undefeated_streak'] = get_streak(team2_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team2_losing_streak'] = get_streak(team2_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team2_without_winning_streak'] = get_streak(team2_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_2'] = team2_games.tail(5)['team_result'].mean()\n",
    "        stats['team2_strength'] = team2_games['team_goals'].sum() / (team2_games['team1_goals'].sum() + team2_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_2'] = team2_games['team_result'].sum() / len(team2_games)\n",
    "        rested_4_or_more_days_2 = team2_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_2'] = 1 if rested_4_or_more_days_2 else -1\n",
    "\n",
    "    return pd.Series(stats)\n",
    "\n",
    "combined_df_13c = pd.concat([combined_df_13c, combined_df_13c.apply(lambda row: get_team_stats(row, combined_df_13c), axis=1)], axis=1)\n",
    "\n",
    "# Now, calculate the number of suspended players for the next match for each team.\n",
    "for team_name in team_df_dict.keys():\n",
    "    team_df = team_df_dict[team_name].copy()\n",
    "    team_df['next_match_suspended_players'] = team_df['team_redcards'].shift()\n",
    "\n",
    "    # Assign the suspended players back to the combined_df_13c.\n",
    "    team1_mask = combined_df_13c['team1'] == team_name\n",
    "    team2_mask = combined_df_13c['team2'] == team_name\n",
    "    combined_df_13c.loc[team1_mask, 'team1_suspended_players'] = team_df.loc[team1_mask, 'next_match_suspended_players']\n",
    "    combined_df_13c.loc[team2_mask, 'team2_suspended_players'] = team_df.loc[team2_mask, 'next_match_suspended_players']\n",
    "\n",
    "combined_df_13c.shape    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66840, 99)\n"
     ]
    }
   ],
   "source": [
    "# Replace empty strings with NaN\n",
    "combined_df_13c.replace('', np.nan, inplace=True)\n",
    "\n",
    "# Remove rows that contain any missing values\n",
    "combined_df_13c.dropna(inplace=True)\n",
    "\n",
    "# Convert the date column to datetime objects (Brazilian format) and handle invalid dates\n",
    "combined_df_13c['date'] = pd.to_datetime(combined_df_13c['date'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "\n",
    "dataset = combined_df_13c.copy()\n",
    "\n",
    "# Sort the dataset by date\n",
    "dataset.sort_values(by='date', inplace=True)\n",
    "\n",
    "# Convert team names to lowercase\n",
    "dataset['team1'] = dataset['team1'].str.lower()\n",
    "dataset['team2'] = dataset['team2'].str.lower()\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "print(dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E0' 'SC0' 'E1' 'E3' 'E2' 'I1' 'SP1' 'D1' 'F1' 'D2' 'P1' 'T1' 'SP2' 'N1'\n",
      " 'I2' 'F2' 'B1' 'G1']\n"
     ]
    }
   ],
   "source": [
    "champ_uniques = dataset['championship'].unique()\n",
    "print(champ_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(66840, 99)\n"
     ]
    }
   ],
   "source": [
    "nan_counts = dataset.isna().sum()\n",
    "nan_tot = nan_counts.sum()\n",
    "print(nan_tot)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar para pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_13c.to_pickle(\"dataset_99cols_europeu.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(66840, 99)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_pickle(\"dataset_99cols_europeu.pkl\")\n",
    "\n",
    "nan_counts = dataset.isna().sum()\n",
    "nan_tot = nan_counts.sum()\n",
    "print(nan_tot)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os dataframes de 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe2023_BRA_A.xlsx\n",
      "(372, 19)\n",
      "team1                      0\n",
      "team2                      0\n",
      "team1_goals              193\n",
      "team2_goals              193\n",
      "season                     0\n",
      "championship               0\n",
      "team1_shots_on_target    193\n",
      "team1_shots_out          193\n",
      "team2_shots_on_target    193\n",
      "team2_shots_out          193\n",
      "team1_red_cards          193\n",
      "team2_red_cards          193\n",
      "team1_fouls              193\n",
      "team2_fouls              193\n",
      "team1_corners            193\n",
      "team2_corners            193\n",
      "team1_total_shots        193\n",
      "team2_total_shots        193\n",
      "date                       0\n",
      "dtype: int64\n",
      "dataframe2023_SUE_A.xlsx\n",
      "(233, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              88\n",
      "team2_goals              88\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    90\n",
      "team1_shots_out          90\n",
      "team2_shots_on_target    90\n",
      "team2_shots_out          90\n",
      "team1_red_cards          88\n",
      "team2_red_cards          88\n",
      "team1_fouls              88\n",
      "team2_fouls              88\n",
      "team1_corners            88\n",
      "team2_corners            88\n",
      "team1_total_shots        90\n",
      "team2_total_shots        90\n",
      "date                      0\n",
      "dtype: int64\n",
      "Index(['team1', 'team2', 'team1_goals', 'team2_goals', 'season',\n",
      "       'championship', 'team1_shots_on_target', 'team1_shots_out',\n",
      "       'team2_shots_on_target', 'team2_shots_out', 'team1_red_cards',\n",
      "       'team2_red_cards', 'team1_fouls', 'team2_fouls', 'team1_corners',\n",
      "       'team2_corners', 'team1_total_shots', 'team2_total_shots', 'date',\n",
      "       'is_future_match'],\n",
      "      dtype='object')\n",
      "(605, 20)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Caminho para a pasta que contém os arquivos .xlsx de 2023\n",
    "path = r'C:\\Users\\mathe\\OneDrive\\Área de Trabalho\\SoccerIA\\webScrappingOddspedia'\n",
    "\n",
    "# Dicionário para armazenar os dataframes\n",
    "dataframes = {}\n",
    "dfss = []\n",
    "# Lista todos os arquivos na pasta\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Filtra a lista de arquivos para incluir apenas os arquivos .xlsx\n",
    "xlsx_files = [f for f in files if f.endswith('.xlsx')]\n",
    "\n",
    "# Carrega cada arquivo .xlsx em um dataframe e armazena no dicionário\n",
    "for file in xlsx_files:\n",
    "    full_path = os.path.join(path, file)  # junta o caminho do diretório com o nome do arquivo\n",
    "    dataframes[file] = pd.read_excel(full_path)  # lê o arquivo .xlsx do caminho completo\n",
    "\n",
    "    if \"Unnamed: 0\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "    if \"match_report_url\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"match_report_url\", axis=1, inplace=True)    \n",
    "\n",
    "    if \"team1_yellow_cards\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"team1_yellow_cards\", axis=1, inplace=True)\n",
    "\n",
    "    if \"team2_yellow_cards\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"team2_yellow_cards\", axis=1, inplace=True)  \n",
    "    dfss.append(dataframes[file])\n",
    "\n",
    "    print(file)\n",
    "    print(dataframes[file].shape)\n",
    "    nan_counts = dataframes[file].isna().sum()\n",
    "    print(nan_counts)\n",
    "\n",
    "\n",
    "# Combine all the DataFrames into a single DataFrame\n",
    "combined_df_2023 = pd.concat(dfss, ignore_index=True)\n",
    "\n",
    "\n",
    "combined_df_2023['team1'] = combined_df_2023['team1'].str.lower()\n",
    "combined_df_2023['team2'] = combined_df_2023['team2'].str.lower()\n",
    "combined_df_2023.replace('', np.nan, inplace=True)\n",
    "# Add a column to mark future matches\n",
    "combined_df_2023['is_future_match'] = combined_df_2023['team1_goals'].isna() | combined_df_2023['team2_goals'].isna()\n",
    "combined_df_2023['season'] = '2023'\n",
    "# Replace empty string with NaN\n",
    "combined_df_2023[\"team1_red_cards\"].replace('', np.nan, inplace=True)\n",
    "combined_df_2023[\"team2_red_cards\"].replace('', np.nan, inplace=True)\n",
    "\n",
    "# Replace NaN with 0\n",
    "combined_df_2023[\"team1_red_cards\"].fillna(0, inplace=True)\n",
    "combined_df_2023[\"team2_red_cards\"].fillna(0, inplace=True)\n",
    "\n",
    "combined_df_2023['date'] = pd.to_datetime(combined_df_2023['date'], format='%Y-%m-%d', errors='coerce')\n",
    "combined_df_2023.sort_values('date', inplace=True)\n",
    "\n",
    "print(combined_df_2023.columns)\n",
    "print(combined_df_2023.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(605, 78)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "combined_df_2023.sort_values('date', inplace=True)\n",
    "\n",
    "\n",
    "combined_df_2023['team1_goals'] = pd.to_numeric(combined_df_2023['team1_goals'], errors='coerce')\n",
    "combined_df_2023['team2_goals'] = pd.to_numeric(combined_df_2023['team2_goals'], errors='coerce')\n",
    "\n",
    "# calculate goal differences\n",
    "combined_df_2023['goal_diff_team1'] = combined_df_2023['team1_goals'] - combined_df_2023['team2_goals']\n",
    "combined_df_2023['goal_diff_team2'] = combined_df_2023['team2_goals'] - combined_df_2023['team1_goals']\n",
    "\n",
    "\n",
    "# calculate big wins and losses\n",
    "combined_df_2023['team1_big_win'] = np.where(combined_df_2023['goal_diff_team1'] >= 2, 1, 0)\n",
    "combined_df_2023['team1_big_loss'] = np.where(combined_df_2023['goal_diff_team1'] <= -2, 1, 0)\n",
    "combined_df_2023['team2_big_win'] = np.where(combined_df_2023['goal_diff_team2'] >= 2, 1, 0)\n",
    "combined_df_2023['team2_big_loss'] = np.where(combined_df_2023['goal_diff_team2'] <= -2, 1, 0)\n",
    "\n",
    "# Initialize big win/loss columns for future matches\n",
    "combined_df_2023['team1_big_wins_last5'] = 0\n",
    "combined_df_2023['team1_big_losses_last5'] = 0\n",
    "combined_df_2023['team2_big_wins_last5'] = 0\n",
    "combined_df_2023['team2_big_losses_last5'] = 0\n",
    "\n",
    "\n",
    "new_cols = ['avg_scr_lasts3_1_home', 'avg_scr_lasts5_1_home', 'avg_scr_lasts3_1_away',\n",
    "            'avg_scr_lasts5_1_away', 'avg_conc_lasts3_1_home', 'avg_conc_lasts5_1_home',\n",
    "            'avg_conc_lasts3_1_away', 'avg_conc_lasts5_1_away', 'avg_scr_lasts3_2_home',\n",
    "            'avg_scr_lasts5_2_home', 'avg_scr_lasts3_2_away', 'avg_scr_lasts5_2_away',\n",
    "            'avg_conc_lasts3_2_home', 'avg_conc_lasts5_2_home', 'avg_conc_lasts3_2_away',\n",
    "            'avg_conc_lasts5_2_away','team1_big_wins_last5', 'team1_big_losses_last5', \n",
    "            'team2_big_wins_last5', 'team2_big_losses_last5',\n",
    "            #abaixo vai ser baseado em finalizações\n",
    "            'avg_total_shots_lasts5_1_home','avg_total_shots_lasts5_1_away','avg_total_shots_lasts5_2_home',\n",
    "            'avg_total_shots_lasts5_2_away', 'avg_otarget_shots_lasts5_1_home','avg_otarget_shots_lasts5_1_away',\n",
    "            'avg_otarget_shots_lasts5_2_home','avg_otarget_shots_lasts5_2_away','avg_out_shots_lasts5_1_home',\n",
    "            'avg_out_shots_lasts5_1_away','avg_out_shots_lasts5_2_home','avg_out_shots_lasts5_2_away',\n",
    "            'avg_conc_total_shots_lasts5_1_home','avg_conc_total_shots_lasts5_1_away',\n",
    "            'avg_conc_total_shots_lasts5_2_home','avg_conc_total_shots_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em corners\n",
    "            'avg_corners_lasts5_1_home','avg_corners_lasts5_1_away', \n",
    "            'avg_corners_conc_lasts5_1_home','avg_corners_conc_lasts5_1_away',\n",
    "            'avg_corners_lasts5_2_home','avg_corners_lasts5_2_away', \n",
    "            'avg_corners_conc_lasts5_2_home', 'avg_corners_conc_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em fouls\n",
    "            'avg_fouls_lasts5_1_home','avg_fouls_lasts5_1_away', \n",
    "            'avg_fouls_conc_lasts5_1_home', 'avg_fouls_conc_lasts5_1_away',\n",
    "            'avg_fouls_lasts5_2_home','avg_fouls_lasts5_2_away', \n",
    "            'avg_fouls_conc_lasts5_2_home', 'avg_fouls_conc_lasts5_2_away'\n",
    "            \n",
    "            ]\n",
    "\n",
    "for col in new_cols:\n",
    "    combined_df_2023[col] = np.nan\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for i, row in combined_df_2023.iterrows():\n",
    "    # For each team, get their past home and away matches before the current date\n",
    "    team1_matches = combined_df_2023[((combined_df_2023['team1'] == row['team1']) | (combined_df_2023['team2'] == row['team1'])) & (combined_df_2023['date'] < row['date']) & (combined_df_2023['season'] == row['season'])].sort_values(by='date')\n",
    "    team2_matches = combined_df_2023[((combined_df_2023['team1'] == row['team2']) | (combined_df_2023['team2'] == row['team2'])) & (combined_df_2023['date'] < row['date']) & (combined_df_2023['season'] == row['season'])].sort_values(by='date')\n",
    "\n",
    "    # For each team, calculate stats for last 5 matches\n",
    "    if not team1_matches.empty:\n",
    "        team1_matches['big_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_win'], team1_matches['team2_big_win'])\n",
    "        team1_matches['big_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_loss'], team1_matches['team2_big_loss'])\n",
    "        combined_df_2023.at[i, 'team1_big_wins_last5'] = team1_matches['big_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_big_losses_last5'] = team1_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "    if not team2_matches.empty:\n",
    "        team2_matches['big_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_win'], team2_matches['team2_big_win'])\n",
    "        team2_matches['big_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_loss'], team2_matches['team2_big_loss'])\n",
    "        combined_df_2023.at[i, 'team2_big_wins_last5'] = team2_matches['big_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_big_losses_last5'] = team2_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "    \n",
    "for i, row in combined_df_2023.iterrows():\n",
    "    team1_home = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team1'] == row['team1']) & (combined_df_2023['season'] == row['season'])]\n",
    "    team1_away = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team2'] == row['team1']) & (combined_df_2023['season'] == row['season'])]\n",
    "    \n",
    "    team2_home = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team1'] == row['team2']) & (combined_df_2023['season'] == row['season'])]\n",
    "    team2_away = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team2'] == row['team2']) & (combined_df_2023['season'] == row['season'])]\n",
    "\n",
    "    if not team1_home.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_1_home'] = team1_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_1_home'] = team1_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_1_home'] = team1_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_1_home'] = team1_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_1_home'] = team1_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_1_home'] = team1_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_1_home'] = team1_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_1_home'] = team1_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_out'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_1_home'] = team1_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_1_home'] = team1_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_1_home'] = team1_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_1_home'] = team1_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team1_away.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_1_away'] = team1_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_1_away'] = team1_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_1_away'] = team1_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_1_away'] = team1_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_1_away'] = team1_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_1_away'] = team1_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_1_away'] = team1_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_1_away'] = team1_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_1_away'] = team1_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_1_away'] = team1_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_1_away'] = team1_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_1_away'] = team1_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team2_home.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_2_home'] = team2_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_2_home'] = team2_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_2_home'] = team2_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_2_home'] = team2_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_2_home'] = team2_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_2_home'] = team2_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_2_home'] = team2_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_2_home'] = team2_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_2_home'] = team2_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_2_home'] = team2_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_2_home'] = team2_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_2_home'] = team2_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "\n",
    "    if not team2_away.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_2_away'] = team2_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_2_away'] = team2_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_2_away'] = team2_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_2_away'] = team2_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_2_away'] = team2_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_2_away'] = team2_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_2_away'] = team2_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_2_away'] = team2_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_2_away'] = team2_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_2_away'] = team2_away['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_2_away'] = team2_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_2_away'] = team2_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_fouls'].isna().any() else np.nan\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_df_2023.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(605, 98)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_result(row):\n",
    "    if row['team1_goals'] > row['team2_goals']:\n",
    "        return pd.Series([3, 0])\n",
    "    elif row['team1_goals'] < row['team2_goals']:\n",
    "        return pd.Series([0, 3])\n",
    "    else:\n",
    "        return pd.Series([1, 1])\n",
    "\n",
    "combined_df_2023[['result_team1', 'result_team2']] = combined_df_2023.apply(get_result, axis=1)\n",
    "\n",
    "def get_streak(df, result_col, results):\n",
    "    result_series = df[result_col].apply(lambda x: 1 if x in results else 0)\n",
    "    result_series = result_series * (result_series.groupby((result_series != result_series.shift()).cumsum()).cumcount() + 1)\n",
    "    return result_series\n",
    "\n",
    "# Create a dictionary to hold individual team dataframes\n",
    "team_df_dict = {}\n",
    "\n",
    "def get_individual_team_df(df, team_name): #teoricamente aqui deveria ser corners, mas o erro se apresentou menor assim:\n",
    "    if team_name in team_df_dict:\n",
    "        return team_df_dict[team_name]\n",
    "        \n",
    "    team_games = df[(df['team1'] == team_name) | (df['team2'] == team_name)].copy()\n",
    "    team_games['team_is_team1'] = team_games['team1'] == team_name\n",
    "    team_games['team_result'] = np.where(team_games['team_is_team1'], team_games['result_team1'], team_games['result_team2'])\n",
    "    team_games['team_goals'] = np.where(team_games['team_is_team1'], team_games['team1_goals'], team_games['team2_goals'])\n",
    "    team_games['team_redcards'] = np.where(team_games['team_is_team1'], team_games['team1_red_cards'], team_games['team2_red_cards'])\n",
    "\n",
    "    team_games.sort_values('date', inplace=True)\n",
    "    team_games['days_since_last_game'] = team_games['date'].diff().dt.days\n",
    "\n",
    "    team_df_dict[team_name] = team_games\n",
    "    return team_games\n",
    "\n",
    "def get_team_stats(row, df):\n",
    "    team1_games = get_individual_team_df(df, row['team1'])\n",
    "    team2_games = get_individual_team_df(df, row['team2'])\n",
    "\n",
    "    # Filter to include only games that occurred before the current game\n",
    "    team1_games = team1_games[team1_games['date'] < row['date']]\n",
    "    team2_games = team2_games[team2_games['date'] < row['date']]\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    if not team1_games.empty:\n",
    "        stats['team1_winning_streak'] = get_streak(team1_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team1_undefeated_streak'] = get_streak(team1_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team1_losing_streak'] = get_streak(team1_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team1_without_winning_streak'] = get_streak(team1_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_1'] = team1_games.tail(5)['team_result'].mean()\n",
    "        stats['team1_strength'] = team1_games['team_goals'].sum() / (team1_games['team1_goals'].sum() + team1_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_1'] = team1_games['team_result'].sum() / len(team1_games)\n",
    "        rested_4_or_more_days_1 = team1_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_1'] = 1 if rested_4_or_more_days_1 else -1\n",
    "\n",
    "    if not team2_games.empty:\n",
    "        stats['team2_winning_streak'] = get_streak(team2_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team2_undefeated_streak'] = get_streak(team2_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team2_losing_streak'] = get_streak(team2_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team2_without_winning_streak'] = get_streak(team2_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_2'] = team2_games.tail(5)['team_result'].mean()\n",
    "        stats['team2_strength'] = team2_games['team_goals'].sum() / (team2_games['team1_goals'].sum() + team2_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_2'] = team2_games['team_result'].sum() / len(team2_games)\n",
    "        rested_4_or_more_days_2 = team2_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_2'] = 1 if rested_4_or_more_days_2 else -1\n",
    "\n",
    "    return pd.Series(stats)\n",
    "\n",
    "combined_df_2023 = pd.concat([combined_df_2023, combined_df_2023.apply(lambda row: get_team_stats(row, combined_df_2023), axis=1)], axis=1)\n",
    "\n",
    "# Now, calculate the number of suspended players for the next match for each team.\n",
    "for team_name in team_df_dict.keys():\n",
    "    team_df = team_df_dict[team_name].copy()\n",
    "    team_df['next_match_suspended_players'] = team_df['team_redcards'].shift()\n",
    "\n",
    "    # Assign the suspended players back to the combined_df_2023.\n",
    "    team1_mask = combined_df_2023['team1'] == team_name\n",
    "    team2_mask = combined_df_2023['team2'] == team_name\n",
    "    combined_df_2023.loc[team1_mask, 'team1_suspended_players'] = team_df.loc[team1_mask, 'next_match_suspended_players']\n",
    "    combined_df_2023.loc[team2_mask, 'team2_suspended_players'] = team_df.loc[team2_mask, 'next_match_suspended_players']\n",
    "\n",
    "combined_df_2023.shape    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEPARANDO AS CLUSTERIZAÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358817, 97)\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Filtrando as linhas com 'championship'\n",
    "ALE_A_df = dataset[dataset['championship'].isin(['D1', 'D2', 'T1', 'B1', 'N1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ALE_A_df['championship'] = 'ALE A'\n",
    "##############################################################################################################\n",
    "# Filtrando as linhas com 'championship'\n",
    "ALE_B_df = dataset[dataset['championship'].isin(['D1', 'D2', 'T1', 'B1', 'N1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ALE_B_df['championship'] = 'ALE B'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "BEL_A_df = dataset[dataset['championship'].isin(['B1', 'D1', 'D2', 'T1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "BEL_A_df['championship'] = 'BEL A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "ESC_A_df = dataset[dataset['championship'].isin(['SC0', 'E2', 'E3', 'P1', 'E1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ESC_A_df['championship'] = 'ESC A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "ESP_A_df = dataset[dataset['championship'].isin(['SP1','I1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ESP_A_df['championship'] = 'ESP A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "ESP_B_df = dataset[dataset['championship'].isin(['SP2', 'F1', 'F2'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ESP_B_df['championship'] = 'ESP B'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "FRA_A_df = dataset[dataset['championship'].isin(['F1', 'I2', 'SP1', 'I1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "FRA_A_df['championship'] = 'FRA A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "FRA_B_df = dataset[dataset['championship'].isin(['F2', 'SP2', 'G1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "FRA_B_df['championship'] = 'FRA B'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "GRE_A_df = dataset[dataset['championship'].isin(['G1', 'F2'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "GRE_A_df['championship'] = 'GRE A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "HOL_A_df = dataset[dataset['championship'].isin(['D1', 'D2'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "HOL_A_df['championship'] = 'HOL A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "ING_A_df = dataset[dataset['championship'].isin(['E0', 'E1', 'E2', 'I1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ING_A_df['championship'] = 'ING A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "ING_B_df = dataset[dataset['championship'].isin(['E1', 'E0', 'E2', 'E3', 'I1', 'P1', 'SC0'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ING_B_df['championship'] = 'ING B'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "ING_C_df = dataset[dataset['championship'].isin(['E2', 'E3', 'E1', 'SC0', 'P1', 'E0'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ING_C_df['championship'] = 'ING C'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "ING_D_df = dataset[dataset['championship'].isin(['E3', 'E2', 'SC0', 'E1', 'P1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ING_D_df['championship'] = 'ING D'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "ITA_A_df = dataset[dataset['championship'].isin(['I1', 'P1', 'E1', 'E0', 'I2'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ITA_A_df['championship'] = 'ITA A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "ITA_B_df = dataset[dataset['championship'].isin(['I2', 'P1', 'F1', 'I2'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "ITA_B_df['championship'] = 'ITA B'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "POR_A_df = dataset[dataset['championship'].isin(['P1', 'E3', 'I2', 'I1', 'E1', 'E2', 'E3','SC0'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "POR_A_df['championship'] = 'POR A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "TUR_A_df = dataset[dataset['championship'].isin(['T1', 'B1', 'D1'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "TUR_A_df['championship'] = 'TUR A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "BRA_A_df = dataset[dataset['championship'].isin(['E3', 'E2', 'SC0'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "BRA_A_df['championship'] = 'BRA A'\n",
    "##############################################################################################################\n",
    "\n",
    "# Filtrando as linhas com 'championship'\n",
    "SUE_A_df = dataset[dataset['championship'].isin(['E3', 'E2', 'SC0'])].copy()\n",
    "\n",
    "# Modificando os valores da coluna 'championship'\n",
    "SUE_A_df['championship'] = 'SUE A'\n",
    "##############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Concatenando o DataFrame original com o novo DataFrame\n",
    "combined_df_13c_new = pd.concat([\n",
    "    ALE_A_df, ALE_B_df, BEL_A_df, ESC_A_df, ESP_A_df, ESP_B_df, \n",
    "    FRA_A_df, FRA_B_df, GRE_A_df, HOL_A_df, ING_A_df, ING_B_df,\n",
    "    ING_C_df, ING_D_df, ITA_A_df, ITA_B_df, POR_A_df, TUR_A_df,\n",
    "    BRA_A_df, SUE_A_df\n",
    "                        ], ignore_index=True)\n",
    "\n",
    "if 'team2_yellow_cards' in combined_df_13c_new.columns:\n",
    "    combined_df_13c_new.drop(['team1_yellow_cards'], axis=1, inplace=True)\n",
    "\n",
    "if 'team2_yellow_cards' in combined_df_13c_new.columns:\n",
    "    combined_df_13c_new.drop(['team2_yellow_cards'], axis=1, inplace=True)\n",
    "\n",
    "# Verificando o resultado\n",
    "print(combined_df_13c_new.shape)\n",
    "nan_counts = combined_df_13c_new.isna().sum()\n",
    "print(list(nan_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "unique_to_df = set(combined_df_13c_new.columns) - set(combined_df_2023.columns)\n",
    "print(unique_to_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o future match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281, 98)\n",
      "(13, 98)\n"
     ]
    }
   ],
   "source": [
    "dataset2 = combined_df_2023.copy()\n",
    "\n",
    "# filter the DataFrame\n",
    "future_matches = dataset2[dataset2['is_future_match'] == True]\n",
    "future_matches.sort_values(by='date')\n",
    "print(future_matches.shape)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get yesterday's date\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "\n",
    "# Filter the DataFrame to include only rows with dates greater than yesterday\n",
    "future_matches = future_matches[future_matches['date'] > yesterday]\n",
    "\n",
    "# Liste todas as colunas que você deseja verificar\n",
    "columns_to_check = [col for col in future_matches.columns if col not in ['team1_goals', 'team2_goals','goal_diff_team1','goal_diff_team2', 'team1_corners', 'team2_corners', 'team1_fouls', 'team2_fouls',\n",
    "                                'team1_shots_on_target', 'team1_total_shots', 'team1_shots_out', 'team2_shots_on_target', 'team2_total_shots', 'team2_shots_out']]\n",
    "\n",
    "# Drop as linhas com 'np.nan' nas colunas especificadas\n",
    "future_matches = future_matches.dropna(subset=columns_to_check)\n",
    "\n",
    "\"\"\"# Contando os valores NaN em cada coluna\n",
    "nan_counts = future_matches.isna().sum()\n",
    "\n",
    "# Transformando em uma lista de pares (nome da coluna, contagem de np.nan)\n",
    "nan_list = list(nan_counts.items())\n",
    "\n",
    "# Percorrendo a lista e imprimindo cada valor individualmente com o nome da coluna\n",
    "for col_name, nan_count in nan_list:\n",
    "    print(f'{col_name}: {nan_count}')\"\"\"\n",
    "    \n",
    "print(future_matches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 98)\n",
      "A quantidade de np.nan em linhas eram 19864\n",
      "Total number of rows with 'NaN' or an empty value: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(228, 98)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CORTAR AS LINHAS COM MATCHES FUTUROS AQUI\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "print(dataset2.shape)\n",
    "dataset2.replace('', np.nan, inplace=True)\n",
    "print(f\"A quantidade de np.nan em linhas eram {dataset2.isna().sum().sum()}\")\n",
    "# Remove rows that contain any missing values\n",
    "dataset2.dropna(inplace=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "counter = 0  # Initialize counter\n",
    "for index, row in dataset2.iterrows():\n",
    "    if row.isnull().any() or row.eq('').any():\n",
    "        print(f\"Row {index} contains 'NaN' or an empty value.\")\n",
    "        counter += 1  # Increase counter if condition is met\n",
    "\n",
    "print(f\"Total number of rows with 'NaN' or an empty value: {counter}\")\n",
    "dataset2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenando os 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1_goals</th>\n",
       "      <th>team2_goals</th>\n",
       "      <th>season</th>\n",
       "      <th>championship</th>\n",
       "      <th>team1_shots_on_target</th>\n",
       "      <th>team1_shots_out</th>\n",
       "      <th>team2_shots_on_target</th>\n",
       "      <th>team2_shots_out</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_undefeated_streak</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242354</th>\n",
       "      <td>Everton</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>ITA A</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132268</th>\n",
       "      <td>Everton</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>ING B</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132269</th>\n",
       "      <td>Charlton</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>ING B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666297</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102918</th>\n",
       "      <td>West Brom</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>ING A</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102919</th>\n",
       "      <td>Leeds</td>\n",
       "      <td>Man United</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>ING A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.554939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>corinthians</td>\n",
       "      <td>coritiba</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>BRA A</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.325506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>grêmio</td>\n",
       "      <td>fluminense</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>BRA A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585223</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>red bull bragantino</td>\n",
       "      <td>vasco da gama</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>BRA A</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>palmeiras</td>\n",
       "      <td>cruzeiro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>BRA A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499821</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>mjallby</td>\n",
       "      <td>malmo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>SUE A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730629</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359045 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      team1          team2  team1_goals  team2_goals season  \\\n",
       "242354              Everton  Middlesbrough          2.0          1.0   2002   \n",
       "132268              Everton  Middlesbrough          2.0          1.0   2002   \n",
       "132269             Charlton        Arsenal          0.0          3.0   2002   \n",
       "102918            West Brom    Southampton          1.0          0.0   2002   \n",
       "102919                Leeds     Man United          1.0          0.0   2002   \n",
       "...                     ...            ...          ...          ...    ...   \n",
       "220             corinthians       coritiba          3.0          1.0   2023   \n",
       "215                  grêmio     fluminense          2.0          1.0   2023   \n",
       "225     red bull bragantino  vasco da gama          1.0          1.0   2023   \n",
       "226               palmeiras       cruzeiro          1.0          0.0   2023   \n",
       "227                 mjallby          malmo          1.0          0.0   2023   \n",
       "\n",
       "       championship  team1_shots_on_target  team1_shots_out  \\\n",
       "242354        ITA A                    8.0              5.0   \n",
       "132268        ING B                    8.0              5.0   \n",
       "132269        ING B                    3.0              6.0   \n",
       "102918        ING A                    7.0              4.0   \n",
       "102919        ING A                    2.0              6.0   \n",
       "...             ...                    ...              ...   \n",
       "220           BRA A                    8.0              6.0   \n",
       "215           BRA A                    5.0              4.0   \n",
       "225           BRA A                    8.0              8.0   \n",
       "226           BRA A                    4.0              5.0   \n",
       "227           SUE A                    2.0              0.0   \n",
       "\n",
       "        team2_shots_on_target  team2_shots_out  ...  team1_undefeated_streak  \\\n",
       "242354                    5.0              5.0  ...                      0.0   \n",
       "132268                    5.0              5.0  ...                      0.0   \n",
       "132269                    8.0              2.0  ...                      0.0   \n",
       "102918                    5.0              5.0  ...                      2.0   \n",
       "102919                    5.0              1.0  ...                      1.0   \n",
       "...                       ...              ...  ...                      ...   \n",
       "220                       4.0              4.0  ...                      4.0   \n",
       "215                       7.0              8.0  ...                      0.0   \n",
       "225                       6.0              2.0  ...                      3.0   \n",
       "226                       4.0              3.0  ...                      0.0   \n",
       "227                      10.0              9.0  ...                      1.0   \n",
       "\n",
       "        team1_winning_streak  team1_without_winning_streak  \\\n",
       "242354                   0.0                           3.0   \n",
       "132268                   0.0                           3.0   \n",
       "132269                   0.0                           1.0   \n",
       "102918                   2.0                           0.0   \n",
       "102919                   1.0                           0.0   \n",
       "...                      ...                           ...   \n",
       "220                      0.0                           1.0   \n",
       "215                      0.0                           2.0   \n",
       "225                      2.0                           0.0   \n",
       "226                      0.0                           1.0   \n",
       "227                      1.0                           0.0   \n",
       "\n",
       "        team2_losing_streak  team2_strength  team2_undefeated_streak  \\\n",
       "242354                  0.0        0.665927                      1.0   \n",
       "132268                  0.0        0.665927                      1.0   \n",
       "132269                  0.0        0.666297                      5.0   \n",
       "102918                  0.0        0.332963                      1.0   \n",
       "102919                  1.0        0.554939                      0.0   \n",
       "...                     ...             ...                      ...   \n",
       "220                     2.0        0.325506                      0.0   \n",
       "215                     0.0        0.585223                      2.0   \n",
       "225                     0.0        0.316996                      1.0   \n",
       "226                     0.0        0.499821                      2.0   \n",
       "227                     0.0        0.730629                      2.0   \n",
       "\n",
       "        team2_winning_streak  team2_without_winning_streak  \\\n",
       "242354                   1.0                           0.0   \n",
       "132268                   1.0                           0.0   \n",
       "132269                   1.0                           0.0   \n",
       "102918                   1.0                           0.0   \n",
       "102919                   0.0                           1.0   \n",
       "...                      ...                           ...   \n",
       "220                      0.0                           2.0   \n",
       "215                      2.0                           0.0   \n",
       "225                      1.0                           0.0   \n",
       "226                      0.0                           4.0   \n",
       "227                      1.0                           0.0   \n",
       "\n",
       "       team1_suspended_players team2_suspended_players  \n",
       "242354                     0.0                     0.0  \n",
       "132268                     0.0                     0.0  \n",
       "132269                     0.0                     0.0  \n",
       "102918                     0.0                     0.0  \n",
       "102919                     0.0                     0.0  \n",
       "...                        ...                     ...  \n",
       "220                        0.0                     0.0  \n",
       "215                        0.0                     1.0  \n",
       "225                        0.0                     0.0  \n",
       "226                        0.0                     0.0  \n",
       "227                        0.0                     0.0  \n",
       "\n",
       "[359045 rows x 98 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatotal = pd.concat([dataset2, combined_df_13c_new], ignore_index=True)#mudei o 'dataset' por combined_df_13c_new\n",
    "\n",
    "datatotal.sort_values(by='date', inplace=True)\n",
    "\n",
    "if 'team1_yellow_cards' in datatotal.columns:\n",
    "    datatotal = datatotal.drop(['team1_yellow_cards'], axis=1)\n",
    "\n",
    "if 'team2_yellow_cards' in datatotal.columns:\n",
    "    datatotal = datatotal.drop(['team2_yellow_cards'], axis=1)\n",
    "\n",
    "datatotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ITA A' 'ING B' 'ING A' 'ING C' 'ESC A' 'ING D' 'BRA A' 'SUE A' 'POR A'\n",
      " 'ESP A' 'FRA A' 'BEL A' 'ALE B' 'TUR A' 'HOL A' 'ALE A' 'ITA B' 'ESP B'\n",
      " 'FRA B' 'GRE A']\n"
     ]
    }
   ],
   "source": [
    "champ_uniques = datatotal['championship'].unique()\n",
    "print(champ_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359045, 2)\n",
      "(359045, 2)\n",
      "(359045, 77)\n",
      "Total number of rows with 'NaN' or an empty value: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>championship</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1_red_cards</th>\n",
       "      <th>team2_red_cards</th>\n",
       "      <th>team1_big_wins_last5</th>\n",
       "      <th>team1_big_losses_last5</th>\n",
       "      <th>team2_big_wins_last5</th>\n",
       "      <th>team2_big_losses_last5</th>\n",
       "      <th>avg_scr_lasts3_1_home</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_undefeated_streak</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359040</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>corinthians</td>\n",
       "      <td>coritiba</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>0.183841</td>\n",
       "      <td>-0.978493</td>\n",
       "      <td>1.201443</td>\n",
       "      <td>0.193267</td>\n",
       "      <td>-0.167806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621245</td>\n",
       "      <td>-0.485305</td>\n",
       "      <td>-0.385242</td>\n",
       "      <td>1.351647</td>\n",
       "      <td>-2.293381</td>\n",
       "      <td>-0.662863</td>\n",
       "      <td>-0.568022</td>\n",
       "      <td>0.059203</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359041</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>grêmio</td>\n",
       "      <td>fluminense</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>-0.908235</td>\n",
       "      <td>0.136556</td>\n",
       "      <td>0.131166</td>\n",
       "      <td>0.193267</td>\n",
       "      <td>0.694039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612084</td>\n",
       "      <td>-0.485305</td>\n",
       "      <td>-0.015990</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>1.189180</td>\n",
       "      <td>-0.055769</td>\n",
       "      <td>1.006015</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>2.965899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359042</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>red bull bragantino</td>\n",
       "      <td>vasco da gama</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>0.183841</td>\n",
       "      <td>0.136556</td>\n",
       "      <td>-0.939112</td>\n",
       "      <td>2.468543</td>\n",
       "      <td>-1.029651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312913</td>\n",
       "      <td>1.134243</td>\n",
       "      <td>-0.754495</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>-2.407489</td>\n",
       "      <td>-0.359316</td>\n",
       "      <td>0.218996</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359043</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>palmeiras</td>\n",
       "      <td>cruzeiro</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>1.275917</td>\n",
       "      <td>-0.978493</td>\n",
       "      <td>-0.939112</td>\n",
       "      <td>-0.944372</td>\n",
       "      <td>-0.167806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612084</td>\n",
       "      <td>-0.485305</td>\n",
       "      <td>-0.385242</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>0.044026</td>\n",
       "      <td>-0.055769</td>\n",
       "      <td>-0.568022</td>\n",
       "      <td>0.810288</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359044</th>\n",
       "      <td>SUE A</td>\n",
       "      <td>mjallby</td>\n",
       "      <td>malmo</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>0.183841</td>\n",
       "      <td>-0.978493</td>\n",
       "      <td>1.201443</td>\n",
       "      <td>0.193267</td>\n",
       "      <td>-1.029651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303752</td>\n",
       "      <td>0.324469</td>\n",
       "      <td>-0.754495</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>3.138929</td>\n",
       "      <td>-0.055769</td>\n",
       "      <td>0.218996</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       championship                team1          team2  team1_red_cards  \\\n",
       "359040        BRA A          corinthians       coritiba         -0.28493   \n",
       "359041        BRA A               grêmio     fluminense         -0.28493   \n",
       "359042        BRA A  red bull bragantino  vasco da gama         -0.28493   \n",
       "359043        BRA A            palmeiras       cruzeiro         -0.28493   \n",
       "359044        SUE A              mjallby          malmo         -0.28493   \n",
       "\n",
       "        team2_red_cards  team1_big_wins_last5  team1_big_losses_last5  \\\n",
       "359040        -0.335133              0.183841               -0.978493   \n",
       "359041        -0.335133             -0.908235                0.136556   \n",
       "359042        -0.335133              0.183841                0.136556   \n",
       "359043        -0.335133              1.275917               -0.978493   \n",
       "359044        -0.335133              0.183841               -0.978493   \n",
       "\n",
       "        team2_big_wins_last5  team2_big_losses_last5  avg_scr_lasts3_1_home  \\\n",
       "359040              1.201443                0.193267              -0.167806   \n",
       "359041              0.131166                0.193267               0.694039   \n",
       "359042             -0.939112                2.468543              -1.029651   \n",
       "359043             -0.939112               -0.944372              -0.167806   \n",
       "359044              1.201443                0.193267              -1.029651   \n",
       "\n",
       "        ...  team1_undefeated_streak  team1_winning_streak  \\\n",
       "359040  ...                 0.621245             -0.485305   \n",
       "359041  ...                -0.612084             -0.485305   \n",
       "359042  ...                 0.312913              1.134243   \n",
       "359043  ...                -0.612084             -0.485305   \n",
       "359044  ...                -0.303752              0.324469   \n",
       "\n",
       "        team1_without_winning_streak  team2_losing_streak  team2_strength  \\\n",
       "359040                     -0.385242             1.351647       -2.293381   \n",
       "359041                     -0.015990            -0.531369        1.189180   \n",
       "359042                     -0.754495            -0.531369       -2.407489   \n",
       "359043                     -0.385242            -0.531369        0.044026   \n",
       "359044                     -0.754495            -0.531369        3.138929   \n",
       "\n",
       "        team2_undefeated_streak  team2_winning_streak  \\\n",
       "359040                -0.662863             -0.568022   \n",
       "359041                -0.055769              1.006015   \n",
       "359042                -0.359316              0.218996   \n",
       "359043                -0.055769             -0.568022   \n",
       "359044                -0.055769              0.218996   \n",
       "\n",
       "        team2_without_winning_streak  team1_suspended_players  \\\n",
       "359040                      0.059203                -0.324719   \n",
       "359041                     -0.691882                -0.324719   \n",
       "359042                     -0.691882                -0.324719   \n",
       "359043                      0.810288                -0.324719   \n",
       "359044                     -0.691882                -0.324719   \n",
       "\n",
       "        team2_suspended_players  \n",
       "359040                -0.298225  \n",
       "359041                 2.965899  \n",
       "359042                -0.298225  \n",
       "359043                -0.298225  \n",
       "359044                -0.298225  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the target variables\n",
    "y1 = datatotal[['team1_corners','championship']]\n",
    "y2 = datatotal[['team2_corners','championship']]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "datatotal_copy = datatotal.drop(['is_future_match',\n",
    "                                 'season', 'date', 'team1_goals', 'team2_goals', 'goal_diff_team1', 'goal_diff_team2', 'team1_big_win','team2_big_win','team1_big_loss','team2_big_loss', 'team1_corners', 'team2_corners', 'team1_fouls', 'team2_fouls', 'team1_shots_on_target', 'team1_total_shots', 'team1_shots_out', 'team2_shots_on_target', 'team2_total_shots', 'team2_shots_out'], axis=1)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Identify the columns to scale, excluding 'team1' and 'team2'\n",
    "columns_to_scale = datatotal_copy.drop(['championship','team1', 'team2'], axis=1).columns\n",
    "\n",
    "# Fit the scaler using the data\n",
    "scaler.fit(datatotal_copy[columns_to_scale])\n",
    "\n",
    "# Transform the data\n",
    "dataset_scaled = scaler.transform(datatotal_copy[columns_to_scale])\n",
    "\n",
    "# Create a new DataFrame with the scaled data\n",
    "dataset_scaled = pd.DataFrame(dataset_scaled, columns=columns_to_scale).reset_index(drop=True)\n",
    "\n",
    "# Add back the 'team1' and 'team2' columns\n",
    "dataset_scaled = pd.concat([datatotal[['championship','team1', 'team2']].reset_index(drop=True), dataset_scaled], axis=1)\n",
    "\n",
    "# Scale the future_matches_filtred DataFrame\n",
    "future_matches_filtred_scaled = scaler.transform(future_matches[columns_to_scale])\n",
    "future_matches_filtred_scaled = pd.DataFrame(future_matches_filtred_scaled, columns=columns_to_scale).reset_index(drop=True)\n",
    "future_matches_filtred_scaled = pd.concat([future_matches[['championship','team1', 'team2']].reset_index(drop=True), future_matches_filtred_scaled], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print(y1.shape)\n",
    "print(y2.shape)#print(future_matches_filtred_scaled.shape)\n",
    "print(dataset_scaled.shape)\n",
    "import numpy as np\n",
    "\n",
    "counter = 0  # Initialize counter\n",
    "for index, row in dataset_scaled.iterrows():\n",
    "    if row.isnull().any() or row.eq('').any():\n",
    "        #print(f\"Row {index} contains 'NaN' or an empty value.\")\n",
    "        counter += 1  # Increase counter if condition is met\n",
    "\n",
    "print(f\"Total number of rows with 'NaN' or an empty value: {counter}\")\n",
    "\n",
    "dataset_scaled[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 75)\n",
      "(359045, 75)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>championship</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1_red_cards</th>\n",
       "      <th>team2_red_cards</th>\n",
       "      <th>team1_big_wins_last5</th>\n",
       "      <th>team1_big_losses_last5</th>\n",
       "      <th>team2_big_wins_last5</th>\n",
       "      <th>team2_big_losses_last5</th>\n",
       "      <th>avg_scr_lasts3_1_home</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_undefeated_streak</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ITA A</td>\n",
       "      <td>147</td>\n",
       "      <td>273</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>-0.908235</td>\n",
       "      <td>0.136556</td>\n",
       "      <td>0.131166</td>\n",
       "      <td>-0.944372</td>\n",
       "      <td>0.047655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612084</td>\n",
       "      <td>-0.485305</td>\n",
       "      <td>0.353262</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>2.271338</td>\n",
       "      <td>-0.359316</td>\n",
       "      <td>0.218996</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ING B</td>\n",
       "      <td>147</td>\n",
       "      <td>273</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>-0.908235</td>\n",
       "      <td>0.136556</td>\n",
       "      <td>0.131166</td>\n",
       "      <td>-0.944372</td>\n",
       "      <td>0.047655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612084</td>\n",
       "      <td>-0.485305</td>\n",
       "      <td>0.353262</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>2.271338</td>\n",
       "      <td>-0.359316</td>\n",
       "      <td>0.218996</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ING B</td>\n",
       "      <td>101</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>0.183841</td>\n",
       "      <td>0.136556</td>\n",
       "      <td>1.201443</td>\n",
       "      <td>-0.944372</td>\n",
       "      <td>-0.598728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612084</td>\n",
       "      <td>-0.485305</td>\n",
       "      <td>-0.385242</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>2.276296</td>\n",
       "      <td>0.854870</td>\n",
       "      <td>0.218996</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ING A</td>\n",
       "      <td>451</td>\n",
       "      <td>387</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>2.583600</td>\n",
       "      <td>-0.908235</td>\n",
       "      <td>1.251605</td>\n",
       "      <td>-0.939112</td>\n",
       "      <td>0.193267</td>\n",
       "      <td>-0.598728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>1.134243</td>\n",
       "      <td>-0.754495</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>-2.193380</td>\n",
       "      <td>-0.359316</td>\n",
       "      <td>0.218996</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ING A</td>\n",
       "      <td>240</td>\n",
       "      <td>266</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>2.367993</td>\n",
       "      <td>-0.978493</td>\n",
       "      <td>-0.939112</td>\n",
       "      <td>-0.944372</td>\n",
       "      <td>0.047655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303752</td>\n",
       "      <td>0.324469</td>\n",
       "      <td>-0.754495</td>\n",
       "      <td>0.410139</td>\n",
       "      <td>0.783098</td>\n",
       "      <td>-0.662863</td>\n",
       "      <td>-0.568022</td>\n",
       "      <td>-0.316340</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359040</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>475</td>\n",
       "      <td>476</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>0.183841</td>\n",
       "      <td>-0.978493</td>\n",
       "      <td>1.201443</td>\n",
       "      <td>0.193267</td>\n",
       "      <td>-0.167806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621245</td>\n",
       "      <td>-0.485305</td>\n",
       "      <td>-0.385242</td>\n",
       "      <td>1.351647</td>\n",
       "      <td>-2.293381</td>\n",
       "      <td>-0.662863</td>\n",
       "      <td>-0.568022</td>\n",
       "      <td>0.059203</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359041</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>-0.908235</td>\n",
       "      <td>0.136556</td>\n",
       "      <td>0.131166</td>\n",
       "      <td>0.193267</td>\n",
       "      <td>0.694039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612084</td>\n",
       "      <td>-0.485305</td>\n",
       "      <td>-0.015990</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>1.189180</td>\n",
       "      <td>-0.055769</td>\n",
       "      <td>1.006015</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>2.965899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359042</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>498</td>\n",
       "      <td>502</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>0.183841</td>\n",
       "      <td>0.136556</td>\n",
       "      <td>-0.939112</td>\n",
       "      <td>2.468543</td>\n",
       "      <td>-1.029651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312913</td>\n",
       "      <td>1.134243</td>\n",
       "      <td>-0.754495</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>-2.407489</td>\n",
       "      <td>-0.359316</td>\n",
       "      <td>0.218996</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359043</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>497</td>\n",
       "      <td>477</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>1.275917</td>\n",
       "      <td>-0.978493</td>\n",
       "      <td>-0.939112</td>\n",
       "      <td>-0.944372</td>\n",
       "      <td>-0.167806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612084</td>\n",
       "      <td>-0.485305</td>\n",
       "      <td>-0.385242</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>0.044026</td>\n",
       "      <td>-0.055769</td>\n",
       "      <td>-0.568022</td>\n",
       "      <td>0.810288</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359044</th>\n",
       "      <td>SUE A</td>\n",
       "      <td>495</td>\n",
       "      <td>494</td>\n",
       "      <td>-0.28493</td>\n",
       "      <td>-0.335133</td>\n",
       "      <td>0.183841</td>\n",
       "      <td>-0.978493</td>\n",
       "      <td>1.201443</td>\n",
       "      <td>0.193267</td>\n",
       "      <td>-1.029651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303752</td>\n",
       "      <td>0.324469</td>\n",
       "      <td>-0.754495</td>\n",
       "      <td>-0.531369</td>\n",
       "      <td>3.138929</td>\n",
       "      <td>-0.055769</td>\n",
       "      <td>0.218996</td>\n",
       "      <td>-0.691882</td>\n",
       "      <td>-0.324719</td>\n",
       "      <td>-0.298225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359045 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       championship  team1  team2  team1_red_cards  team2_red_cards  \\\n",
       "0             ITA A    147    273         -0.28493        -0.335133   \n",
       "1             ING B    147    273         -0.28493        -0.335133   \n",
       "2             ING B    101     31         -0.28493        -0.335133   \n",
       "3             ING A    451    387         -0.28493         2.583600   \n",
       "4             ING A    240    266         -0.28493        -0.335133   \n",
       "...             ...    ...    ...              ...              ...   \n",
       "359040        BRA A    475    476         -0.28493        -0.335133   \n",
       "359041        BRA A    486    483         -0.28493        -0.335133   \n",
       "359042        BRA A    498    502         -0.28493        -0.335133   \n",
       "359043        BRA A    497    477         -0.28493        -0.335133   \n",
       "359044        SUE A    495    494         -0.28493        -0.335133   \n",
       "\n",
       "        team1_big_wins_last5  team1_big_losses_last5  team2_big_wins_last5  \\\n",
       "0                  -0.908235                0.136556              0.131166   \n",
       "1                  -0.908235                0.136556              0.131166   \n",
       "2                   0.183841                0.136556              1.201443   \n",
       "3                  -0.908235                1.251605             -0.939112   \n",
       "4                   2.367993               -0.978493             -0.939112   \n",
       "...                      ...                     ...                   ...   \n",
       "359040              0.183841               -0.978493              1.201443   \n",
       "359041             -0.908235                0.136556              0.131166   \n",
       "359042              0.183841                0.136556             -0.939112   \n",
       "359043              1.275917               -0.978493             -0.939112   \n",
       "359044              0.183841               -0.978493              1.201443   \n",
       "\n",
       "        team2_big_losses_last5  avg_scr_lasts3_1_home  ...  \\\n",
       "0                    -0.944372               0.047655  ...   \n",
       "1                    -0.944372               0.047655  ...   \n",
       "2                    -0.944372              -0.598728  ...   \n",
       "3                     0.193267              -0.598728  ...   \n",
       "4                    -0.944372               0.047655  ...   \n",
       "...                        ...                    ...  ...   \n",
       "359040                0.193267              -0.167806  ...   \n",
       "359041                0.193267               0.694039  ...   \n",
       "359042                2.468543              -1.029651  ...   \n",
       "359043               -0.944372              -0.167806  ...   \n",
       "359044                0.193267              -1.029651  ...   \n",
       "\n",
       "        team1_undefeated_streak  team1_winning_streak  \\\n",
       "0                     -0.612084             -0.485305   \n",
       "1                     -0.612084             -0.485305   \n",
       "2                     -0.612084             -0.485305   \n",
       "3                      0.004581              1.134243   \n",
       "4                     -0.303752              0.324469   \n",
       "...                         ...                   ...   \n",
       "359040                 0.621245             -0.485305   \n",
       "359041                -0.612084             -0.485305   \n",
       "359042                 0.312913              1.134243   \n",
       "359043                -0.612084             -0.485305   \n",
       "359044                -0.303752              0.324469   \n",
       "\n",
       "        team1_without_winning_streak  team2_losing_streak  team2_strength  \\\n",
       "0                           0.353262            -0.531369        2.271338   \n",
       "1                           0.353262            -0.531369        2.271338   \n",
       "2                          -0.385242            -0.531369        2.276296   \n",
       "3                          -0.754495            -0.531369       -2.193380   \n",
       "4                          -0.754495             0.410139        0.783098   \n",
       "...                              ...                  ...             ...   \n",
       "359040                     -0.385242             1.351647       -2.293381   \n",
       "359041                     -0.015990            -0.531369        1.189180   \n",
       "359042                     -0.754495            -0.531369       -2.407489   \n",
       "359043                     -0.385242            -0.531369        0.044026   \n",
       "359044                     -0.754495            -0.531369        3.138929   \n",
       "\n",
       "        team2_undefeated_streak  team2_winning_streak  \\\n",
       "0                     -0.359316              0.218996   \n",
       "1                     -0.359316              0.218996   \n",
       "2                      0.854870              0.218996   \n",
       "3                     -0.359316              0.218996   \n",
       "4                     -0.662863             -0.568022   \n",
       "...                         ...                   ...   \n",
       "359040                -0.662863             -0.568022   \n",
       "359041                -0.055769              1.006015   \n",
       "359042                -0.359316              0.218996   \n",
       "359043                -0.055769             -0.568022   \n",
       "359044                -0.055769              0.218996   \n",
       "\n",
       "        team2_without_winning_streak  team1_suspended_players  \\\n",
       "0                          -0.691882                -0.324719   \n",
       "1                          -0.691882                -0.324719   \n",
       "2                          -0.691882                -0.324719   \n",
       "3                          -0.691882                -0.324719   \n",
       "4                          -0.316340                -0.324719   \n",
       "...                              ...                      ...   \n",
       "359040                      0.059203                -0.324719   \n",
       "359041                     -0.691882                -0.324719   \n",
       "359042                     -0.691882                -0.324719   \n",
       "359043                      0.810288                -0.324719   \n",
       "359044                     -0.691882                -0.324719   \n",
       "\n",
       "        team2_suspended_players  \n",
       "0                     -0.298225  \n",
       "1                     -0.298225  \n",
       "2                     -0.298225  \n",
       "3                     -0.298225  \n",
       "4                     -0.298225  \n",
       "...                         ...  \n",
       "359040                -0.298225  \n",
       "359041                 2.965899  \n",
       "359042                -0.298225  \n",
       "359043                -0.298225  \n",
       "359044                -0.298225  \n",
       "\n",
       "[359045 rows x 75 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Preprocess the dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encode the team names\n",
    "teams = pd.concat([dataset_scaled['team1'], dataset_scaled['team2']]).astype(str)\n",
    "le = LabelEncoder().fit(teams)\n",
    "\n",
    "dataset_scaled['team1'] = le.transform(dataset_scaled['team1'].astype(str))\n",
    "dataset_scaled['team2'] = le.transform(dataset_scaled['team2'].astype(str))\n",
    "\n",
    "# Encode the team names in the future_matches_filtred dataset\n",
    "future_matches_filtred_scaled['team1'] = le.transform(future_matches_filtred_scaled['team1'].astype(str))\n",
    "future_matches_filtred_scaled['team2'] = le.transform(future_matches_filtred_scaled['team2'].astype(str))\n",
    "\n",
    "final_df = dataset_scaled.drop(['result_team1', 'result_team2'], axis=1)\n",
    "future_matches_filtred_scaled = future_matches_filtred_scaled.drop(['result_team1', 'result_team2'], axis=1)\n",
    "\n",
    "print(future_matches_filtred_scaled.shape)\n",
    "print(final_df.shape)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basta rodar até aqui, agora só ir carregar os pickles e receber a output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basta rodar até aqui, agora só ir carregar os pickles e receber a output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basta rodar até aqui, agora só ir carregar os pickles e receber a output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ITA A', 'ING B', 'ING A', 'ING C', 'ESC A', 'ING D', 'BRA A',\n",
       "       'SUE A', 'POR A', 'ESP A', 'FRA A', 'BEL A', 'ALE B', 'TUR A',\n",
       "       'HOL A', 'ALE A', 'ITA B', 'ESP B', 'FRA B', 'GRE A'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['championship'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando X e Y para cada campeonato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Para X\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(final_df\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m final_df \u001b[39m=\u001b[39m final_df\u001b[39m.\u001b[39mdropna()\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(final_df\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Para X\n",
    "print(final_df.shape)\n",
    "final_df = final_df.dropna()\n",
    "print(final_df.shape)\n",
    "\n",
    "grouped_X = final_df.groupby('championship')\n",
    "\n",
    "dfs_X = {name: group.copy() for name, group in grouped_X}\n",
    "\n",
    "# Para Y1 e Y2\n",
    "print(y1.shape)\n",
    "print(y2.shape)\n",
    "\n",
    "y1 = y1.loc[final_df.index]\n",
    "y2 = y2.loc[final_df.index]\n",
    "\n",
    "print(y1.shape)\n",
    "print(y2.shape)\n",
    "\n",
    "grouped_y1 = y1.groupby('championship')\n",
    "grouped_y2 = y2.groupby('championship')\n",
    "\n",
    "dfs_y1 = {name: group.copy() for name, group in grouped_y1}\n",
    "dfs_y2 = {name: group.copy() for name, group in grouped_y2}\n",
    "\n",
    "# Agora você tem três dicionários: dfs_X, dfs_y1, dfs_y2\n",
    "# Cada um com chaves sendo 'championship' e valores sendo os DataFrames correspondentes\n",
    "\n",
    "# Calcule a média de 'team1_corners' e 'team2_corners' para cada campeonato\n",
    "mean_y1 = {championship: df['team1_corners'].mean() for championship, df in dfs_y1.items()}\n",
    "mean_y2 = {championship: df['team2_corners'].mean() for championship, df in dfs_y2.items()}\n",
    "\n",
    "# Removendo a coluna 'championship' de todos os dicionários\n",
    "for df_dict in [dfs_X, dfs_y1, dfs_y2]:\n",
    "    for df in df_dict.values():\n",
    "        if 'championship' in df.columns:\n",
    "            df.drop('championship', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X for each championship:\n",
      "ALE A: (8740, 74)\n",
      "ALE B: (8740, 74)\n",
      "BEL A: (7515, 74)\n",
      "BRA A: (20742, 74)\n",
      "ESC A: (30493, 74)\n",
      "ESP A: (11360, 74)\n",
      "ESP B: (7681, 74)\n",
      "FRA A: (17786, 74)\n",
      "FRA B: (3425, 74)\n",
      "GRE A: (1470, 74)\n",
      "HOL A: (5480, 74)\n",
      "ING A: (29348, 74)\n",
      "ING B: (42704, 74)\n",
      "ING C: (36889, 74)\n",
      "ING D: (30493, 74)\n",
      "ITA A: (23675, 74)\n",
      "ITA B: (7684, 74)\n",
      "POR A: (37894, 74)\n",
      "SUE A: (20716, 74)\n",
      "TUR A: (6210, 74)\n",
      "\n",
      "Shape of y1 for each championship:\n",
      "ALE A: (8740, 1)\n",
      "ALE B: (8740, 1)\n",
      "BEL A: (7515, 1)\n",
      "BRA A: (20742, 1)\n",
      "ESC A: (30493, 1)\n",
      "ESP A: (11360, 1)\n",
      "ESP B: (7681, 1)\n",
      "FRA A: (17786, 1)\n",
      "FRA B: (3425, 1)\n",
      "GRE A: (1470, 1)\n",
      "HOL A: (5480, 1)\n",
      "ING A: (29348, 1)\n",
      "ING B: (42704, 1)\n",
      "ING C: (36889, 1)\n",
      "ING D: (30493, 1)\n",
      "ITA A: (23675, 1)\n",
      "ITA B: (7684, 1)\n",
      "POR A: (37894, 1)\n",
      "SUE A: (20716, 1)\n",
      "TUR A: (6210, 1)\n",
      "\n",
      "Shape of y2 for each championship:\n",
      "ALE A: (8740, 1)\n",
      "ALE B: (8740, 1)\n",
      "BEL A: (7515, 1)\n",
      "BRA A: (20742, 1)\n",
      "ESC A: (30493, 1)\n",
      "ESP A: (11360, 1)\n",
      "ESP B: (7681, 1)\n",
      "FRA A: (17786, 1)\n",
      "FRA B: (3425, 1)\n",
      "GRE A: (1470, 1)\n",
      "HOL A: (5480, 1)\n",
      "ING A: (29348, 1)\n",
      "ING B: (42704, 1)\n",
      "ING C: (36889, 1)\n",
      "ING D: (30493, 1)\n",
      "ITA A: (23675, 1)\n",
      "ITA B: (7684, 1)\n",
      "POR A: (37894, 1)\n",
      "SUE A: (20716, 1)\n",
      "TUR A: (6210, 1)\n"
     ]
    }
   ],
   "source": [
    "# Para dfs_X\n",
    "print(\"Shape of X for each championship:\")\n",
    "for championship, df in dfs_X.items():\n",
    "    print(f\"{championship}: {df.shape}\")\n",
    "\n",
    "# Para dfs_y1\n",
    "print(\"\\nShape of y1 for each championship:\")\n",
    "for championship, df in dfs_y1.items():\n",
    "    print(f\"{championship}: {df.shape}\")\n",
    "\n",
    "# Para dfs_y2\n",
    "print(\"\\nShape of y2 for each championship:\")\n",
    "for championship, df in dfs_y2.items():\n",
    "    print(f\"{championship}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ALE A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.002425322741760353}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0031622776601683794}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 2.0151799712932177\n",
      "Erro relativo a Y_1 : 0.36470446957328645\n",
      "Erro relativo a Y_2 : 0.38734935769381074\n",
      "Minimum median absolute error for Lasso (team2): 1.713865790775441\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ALE A : 0.7520538272670971\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ALE B\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0002557499934506013}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0031622776601683794}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9599989649626413\n",
      "Erro relativo a Y_1 : 0.3547178877637232\n",
      "Erro relativo a Y_2 : 0.38858414247223927\n",
      "Minimum median absolute error for Lasso (team2): 1.7193292189409572\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ALE B : 0.7433020302359625\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "BEL A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0021861469872667748}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0031622776601683794}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.949762798993543\n",
      "Erro relativo a Y_1 : 0.35537501963174495\n",
      "Erro relativo a Y_2 : 0.3812606600126033\n",
      "Minimum median absolute error for Lasso (team2): 1.6784601032411133\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO BEL A : 0.7366356796443483\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "BRA A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.003054709671159968}\n",
      "Best parameters for Lasso (team2): {'alpha': 7.884852748253346e-05}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.981316721666298\n",
      "Erro relativo a Y_1 : 0.3387751233692665\n",
      "Erro relativo a Y_2 : 0.3810028141659924\n",
      "Minimum median absolute error for Lasso (team2): 1.8523143758226226\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO BRA A : 0.7197779375352589\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ESC A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 7.705016038963921e-05}\n",
      "Best parameters for Lasso (team2): {'alpha': 1e-05}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9803619677678916\n",
      "Erro relativo a Y_1 : 0.33797973640460016\n",
      "Erro relativo a Y_2 : 0.38309121351403985\n",
      "Minimum median absolute error for Lasso (team2): 1.8569615707964686\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ESC A : 0.7210709499186401\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ESP A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0026598043955937583}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0031622776601683794}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 2.031539652199592\n",
      "Erro relativo a Y_1 : 0.35186757408348124\n",
      "Erro relativo a Y_2 : 0.391741618881446\n",
      "Minimum median absolute error for Lasso (team2): 1.7416294420429075\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ESP A : 0.7436091929649272\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ESP B\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0031622776601683794}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0019479560691239785}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9190870468027676\n",
      "Erro relativo a Y_1 : 0.3589992110689737\n",
      "Erro relativo a Y_2 : 0.40038507671779755\n",
      "Minimum median absolute error for Lasso (team2): 1.679365449370822\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ESP B : 0.7593842877867713\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "FRA A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0030196730280191864}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.003090152837242533}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9382771453160241\n",
      "Erro relativo a Y_1 : 0.3438308213892266\n",
      "Erro relativo a Y_2 : 0.3786526325167585\n",
      "Minimum median absolute error for Lasso (team2): 1.66851134421657\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO FRA A : 0.7224834539059851\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "FRA B\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.003054709671159968}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0013622867641416468}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9209341941109297\n",
      "Erro relativo a Y_1 : 0.36775850278535127\n",
      "Erro relativo a Y_2 : 0.4267671059999362\n",
      "Minimum median absolute error for Lasso (team2): 1.727877214277698\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO FRA B : 0.7945256087852874\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "GRE A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0020165510387247466}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0011591196185988858}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9676726897824424\n",
      "Erro relativo a Y_1 : 0.39076990731966904\n",
      "Erro relativo a Y_2 : 0.46973678306424693\n",
      "Minimum median absolute error for Lasso (team2): 1.857217811679866\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO GRE A : 0.860506690383916\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "HOL A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0006217090286163827}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.002916955876018796}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9919225563429683\n",
      "Erro relativo a Y_1 : 0.36281777600077997\n",
      "Erro relativo a Y_2 : 0.3934003347848895\n",
      "Minimum median absolute error for Lasso (team2): 1.7352687759891148\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO HOL A : 0.7562181107856695\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ING A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.003090152837242533}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0019705578015017985}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 2.023630715643111\n",
      "Erro relativo a Y_1 : 0.3413268939670683\n",
      "Erro relativo a Y_2 : 0.3878161295272456\n",
      "Minimum median absolute error for Lasso (team2): 1.855539228429766\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ING A : 0.7291430234943139\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ING B\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.002916955876018796}\n",
      "Best parameters for Lasso (team2): {'alpha': 1e-05}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 2.0281014532790516\n",
      "Erro relativo a Y_1 : 0.34520738205179474\n",
      "Erro relativo a Y_2 : 0.3912267396867141\n",
      "Minimum median absolute error for Lasso (team2): 1.8773185138718247\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ING B : 0.7364341217385089\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ING C\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.003090152837242533}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.00017477727744646807}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 2.017269721124938\n",
      "Erro relativo a Y_1 : 0.3419872733992254\n",
      "Erro relativo a Y_2 : 0.383920166749398\n",
      "Minimum median absolute error for Lasso (team2): 1.857010471231582\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ING C : 0.7259074401486234\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ING D\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0031260072430687037}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0003615066015639753}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9940106059182736\n",
      "Erro relativo a Y_1 : 0.34030908992654607\n",
      "Erro relativo a Y_2 : 0.3837755097450987\n",
      "Minimum median absolute error for Lasso (team2): 1.8602785662254715\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ING D : 0.7240845996716447\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ITA A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0031622776601683794}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.00042980012064907985}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 2.05397395512685\n",
      "Erro relativo a Y_1 : 0.35002183424240024\n",
      "Erro relativo a Y_2 : 0.38156995384337894\n",
      "Minimum median absolute error for Lasso (team2): 1.8046042729414697\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ITA A : 0.7315917880857792\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "ITA B\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0031622776601683794}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0027218847945751795}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.943731584162613\n",
      "Erro relativo a Y_1 : 0.3585469918548473\n",
      "Erro relativo a Y_2 : 0.3931788224548376\n",
      "Minimum median absolute error for Lasso (team2): 1.7353799796402676\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO ITA B : 0.7517258143096849\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "POR A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0031622776601683794}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.00023864674269121755}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9892470694581934\n",
      "Erro relativo a Y_1 : 0.3418540552370639\n",
      "Erro relativo a Y_2 : 0.38542064014676286\n",
      "Minimum median absolute error for Lasso (team2): 1.8469759034551898\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO POR A : 0.7272746953838267\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "SUE A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0014939934636052578}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0009527038402822441}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9695555870340695\n",
      "Erro relativo a Y_1 : 0.33698370918744763\n",
      "Erro relativo a Y_2 : 0.38359290987636896\n",
      "Minimum median absolute error for Lasso (team2): 1.8646363209379395\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO SUE A : 0.7205766190638165\n",
      "--------------------------------------------------\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "TUR A\n",
      "\n",
      "Best parameters for Lasso (team1): {'alpha': 0.0021117830444482445}\n",
      "Best parameters for Lasso (team2): {'alpha': 0.0031622776601683794}\n",
      "\n",
      "Minimum median absolute error for Lasso (team1): 1.9870555586024934\n",
      "Erro relativo a Y_1 : 0.36245014007700055\n",
      "Erro relativo a Y_2 : 0.39386473713729075\n",
      "Minimum median absolute error for Lasso (team2): 1.721778747031567\n",
      "\n",
      "\n",
      "Error relativo da COMPETIÇÃO TUR A : 0.7563148772142914\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Hyperparameter grid for Lasso\n",
    "lasso_param_grid = {\n",
    "    'alpha': np.logspace(-5, -2.5, num=500)  \n",
    "}\n",
    "\n",
    "# Use 5 splits\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def perform_grid_search(model, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_median_absolute_error', cv=tscv, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_mae = -1 * grid_search.best_score_ # Switching back to positive MAE, so lower is better\n",
    "    return best_params, best_mae\n",
    "\n",
    "for key in dfs_X.keys(): \n",
    "    # Perform grid search for Lasso models for both teams\n",
    "    best_lasso_params1, min_mae1 = perform_grid_search(Lasso(max_iter=10000000, random_state=42), lasso_param_grid, dfs_X[key], dfs_y1[key])\n",
    "    best_lasso_params2, min_mae2 = perform_grid_search(Lasso(max_iter=10000000, random_state=42), lasso_param_grid, dfs_X[key], dfs_y2[key])\n",
    "    erro_rel_1 = min_mae1/mean_y1[key]\n",
    "    erro_rel_2 = min_mae2/mean_y2[key]\n",
    "    tot_erro_rel = float(erro_rel_2) + float(erro_rel_1)\n",
    "    print(key)\n",
    "    print(f\"\\nBest parameters for Lasso (team1): {best_lasso_params1}\")\n",
    "    print(f\"Best parameters for Lasso (team2): {best_lasso_params2}\\n\")\n",
    "    print(f\"Minimum median absolute error for Lasso (team1): {min_mae1}\")\n",
    "    print(f\"Erro relativo a Y_1 : {erro_rel_1}\")\n",
    "    print(f\"Erro relativo a Y_2 : {erro_rel_2}\")\n",
    "    print(f\"Minimum median absolute error for Lasso (team2): {min_mae2}\\n\\n\")\n",
    "    print(f\"Error relativo da COMPETIÇÃO {key} : {tot_erro_rel}\")\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para armazenar os modelos Lasso\n",
    "models_lasso = {}\n",
    "\n",
    "for key in dfs_X.keys(): \n",
    "    # Criar modelos Lasso com os melhores parâmetros\n",
    "    model1_lasso = Lasso(**best_lasso_params1, max_iter = 10000000)\n",
    "    model2_lasso = Lasso(**best_lasso_params2, max_iter = 10000000)\n",
    "    \n",
    "    # Ajustar os modelos nos dados de treinamento\n",
    "    model1_lasso.fit(dfs_X[key], dfs_y1[key])\n",
    "    model2_lasso.fit(dfs_X[key], dfs_y2[key])\n",
    "\n",
    "    # Adicionar os modelos treinados ao dicionário\n",
    "    models_lasso[key] = {\"model1\": model1_lasso, \"model2\": model2_lasso}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando o treinamento dos modelos em pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Suponhamos que model1_lasso e model2_lasso são seus modelos treinados\n",
    "for key in models_lasso.keys():\n",
    "    with open(f'model1_lasso_{key}.pkl', 'wb') as f:\n",
    "        pickle.dump(models_lasso[key][\"model1\"], f)\n",
    "        \n",
    "    with open(f'model2_lasso_{key}.pkl', 'wb') as f:\n",
    "        pickle.dump(models_lasso[key][\"model2\"], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salvo!\n"
     ]
    }
   ],
   "source": [
    "print(\"salvo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes para I1 - model1_lasso\n",
      "team2_red_cards                       0.160244\n",
      "championship_points_1                 0.126746\n",
      "avg_conc_total_shots_lasts5_2_away    0.075646\n",
      "avg_otarget_shots_lasts5_1_home       0.074293\n",
      "avg_corners_conc_lasts5_2_home        0.043184\n",
      "                                        ...   \n",
      "team1_undefeated_streak              -0.042428\n",
      "championship_points_2                -0.048598\n",
      "team1_yellow_cards                   -0.082801\n",
      "team2_strength                       -0.084431\n",
      "team1_red_cards                      -0.093779\n",
      "Length: 76, dtype: float64\n",
      "\n",
      "\n",
      "Coeficientes para I1 - model2_lasso\n",
      "team1_red_cards                   0.136960\n",
      "championship_points_2             0.082599\n",
      "avg_scr_lasts5_2_away             0.065906\n",
      "avg_corners_conc_lasts5_1_home    0.048653\n",
      "avg_conc_lasts3_1_away            0.045792\n",
      "                                    ...   \n",
      "avg_conc_lasts5_2_home           -0.040928\n",
      "avg_conc_lasts5_2_away           -0.052574\n",
      "avg_fouls_lasts5_1_away          -0.054811\n",
      "team2_red_cards                  -0.060887\n",
      "team1_strength                   -0.099691\n",
      "Length: 76, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"for key, models in models_lasso.items():\n",
    "    model1_lasso = models[\"model1\"]\n",
    "    model2_lasso = models[\"model2\"]\n",
    "    \n",
    "    # Coeficientes para model1_lasso\n",
    "    coef_model1 = pd.Series(model1_lasso.coef_, index=dfs_X[key].columns)\n",
    "    print(f\"Coeficientes para {key} - model1_lasso\")\n",
    "    print(coef_model1.sort_values(ascending=False))  # Ordenando para melhor visualização\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Coeficientes para model2_lasso\n",
    "    coef_model2 = pd.Series(model2_lasso.coef_, index=dfs_X[key].columns)\n",
    "    print(f\"Coeficientes para {key} - model2_lasso\")\n",
    "    print(coef_model2.sort_values(ascending=False))  # Ordenando para melhor visualização\n",
    "    print(\"\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os modelos Lassos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Lista todos os arquivos na pasta atual\n",
    "files_in_directory = os.listdir()\n",
    "\n",
    "# Filtra somente os arquivos .pkl\n",
    "pkl_files = [f for f in files_in_directory if f.endswith('.pkl')]\n",
    "\n",
    "# Dicionário para armazenar os modelos Lasso carregados\n",
    "loaded_models_lasso = {}\n",
    "\n",
    "# Loop para carregar os modelos\n",
    "for file in pkl_files:\n",
    "    # Verifica se o arquivo é um dos arquivos de modelo desejados\n",
    "    if 'model1_lasso_' in file or 'model2_lasso_' in file:\n",
    "        with open(file, 'rb') as f:\n",
    "            model_loaded = pickle.load(f)\n",
    "        \n",
    "        # Extrai a chave e o nome do modelo a partir do nome do arquivo\n",
    "        # Assume que os arquivos têm nomes como 'model1_lasso_BRA A.pkl'\n",
    "        parts = file.split('_')\n",
    "        model_name = parts[0]\n",
    "        key = ' '.join(parts[2:]).replace('.pkl', '')\n",
    "        \n",
    "        # Insere o modelo carregado no dicionário\n",
    "        if key not in loaded_models_lasso:\n",
    "            loaded_models_lasso[key] = {}\n",
    "        \n",
    "        loaded_models_lasso[key][model_name] = model_loaded\n",
    "\n",
    "# Agora, loaded_models_lasso é um dicionário com os modelos Lasso carregados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos carregados:\n",
      "ALE A\n",
      "ALE B\n",
      "BEL A\n",
      "BRA A\n",
      "ESC A\n",
      "ESP A\n",
      "ESP B\n",
      "FRA A\n",
      "FRA B\n",
      "GRE A\n",
      "HOL A\n",
      "ING A\n",
      "ING B\n",
      "ING C\n",
      "ING D\n",
      "ITA A\n",
      "ITA B\n",
      "POR A\n",
      "SUE A\n",
      "TUR A\n"
     ]
    }
   ],
   "source": [
    "# Imprime as chaves do dicionário, que são os nomes dos modelos carregados\n",
    "print(\"Modelos carregados:\")\n",
    "for key in loaded_models_lasso.keys():\n",
    "    print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def poisson_probabilities(lam, max_corners=20):\n",
    "    probs = [poisson.pmf(k, lam) for k in range(max_corners + 1)]\n",
    "    probs.append(1 - sum(probs))\n",
    "    return probs\n",
    "\n",
    "def calculate_probabilities(match_row, model1, model2):\n",
    "    input_data = match_row.copy()  \n",
    "\n",
    "    team1_goal_prediction = model1.predict([input_data])\n",
    "    team2_goal_prediction = model2.predict([input_data])\n",
    "\n",
    "    team1_goal_probabilities = poisson_probabilities(team1_goal_prediction[0])\n",
    "    team2_goal_probabilities = poisson_probabilities(team2_goal_prediction[0])\n",
    "\n",
    "    joint_prob_matrix = np.outer(team1_goal_probabilities, team2_goal_probabilities)\n",
    "\n",
    "    team1_win_prob = np.sum(np.tril(joint_prob_matrix, -1))\n",
    "    draw_prob = np.sum(np.diag(joint_prob_matrix))\n",
    "    team2_win_prob = np.sum(np.triu(joint_prob_matrix, 1))\n",
    "\n",
    "    team1_minus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=3])\n",
    "    team1_plus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=-2])\n",
    "    team2_minus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=3])\n",
    "    team2_plus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=-2])\n",
    "\n",
    "    team1_over45_prob = 1 - sum(team1_goal_probabilities[:5])\n",
    "    team1_under45_prob = sum(team1_goal_probabilities[:5])\n",
    "    team2_over45_prob = 1 - sum(team2_goal_probabilities[:5])\n",
    "    team2_under45_prob = sum(team2_goal_probabilities[:5])\n",
    "\n",
    "    return (team1_win_prob, draw_prob, team2_win_prob, team1_corners, team2_corners,\n",
    "            team1_minus15_prob, team1_plus15_prob, team2_minus15_prob, team2_plus15_prob,\n",
    "            team1_minus25_prob, team1_plus25_prob, team2_minus25_prob, team2_plus25_prob,\n",
    "            team1_over45_prob, team1_under45_prob, team2_over45_prob, team2_under45_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for _, row in future_matches_filtred_scaled.iterrows():\n",
    "    # Descobrir qual modelo usar\n",
    "    championship = row['championship'].upper()  # Converte para maiúsculas para corresponder às chaves em loaded_models_lasso\n",
    "    \n",
    "    # Buscar os modelos apropriados carregados\n",
    "    model1_lasso_loaded = loaded_models_lasso[championship][\"model1\"]\n",
    "    model2_lasso_loaded = loaded_models_lasso[championship][\"model2\"]\n",
    "    \n",
    "    # Remover a coluna 'championship' após ter selecionado o modelo\n",
    "    row = row.drop('championship')\n",
    "    \n",
    "    # Calcular probabilidades (assumindo que você tem uma função para isso)\n",
    "    (team1_win_prob, draw_prob, team2_win_prob, team1_corners, team2_corners,\n",
    "     team1_minus15_prob, team1_plus15_prob, team2_minus15_prob, team2_plus15_prob,\n",
    "     team1_minus25_prob, team1_plus25_prob, team2_minus25_prob, team2_plus25_prob,\n",
    "     team1_over45_prob, team1_under45_prob, team2_over45_prob, team2_under45_prob) = calculate_probabilities(row, model1_lasso_loaded, model2_lasso_loaded)\n",
    "    \n",
    "    output.append([team1_name, team2_name, 1/team1_win_prob, 1/draw_prob, 1/team2_win_prob,\n",
    "                   1/team1_minus15_prob, 1/team1_plus15_prob, 1/team2_minus15_prob, 1/team2_plus15_prob,\n",
    "                   1/team1_minus25_prob, 1/team1_plus25_prob, 1/team2_minus25_prob, 1/team2_plus25_prob,\n",
    "                   1/team1_over45_prob, 1/team1_under45_prob, 1/team2_over45_prob, 1/team2_under45_prob])\n",
    "\n",
    "    \n",
    "    team1_name = le.inverse_transform([int(row['team1'])])[0]\n",
    "    team2_name = le.inverse_transform([int(row['team2'])])[0]\n",
    "    \n",
    "    \n",
    "\n",
    "df_output = pd.DataFrame()\n",
    "\n",
    "df_output['date'] = pd.to_datetime(future_matches['date'].values, format='%d/%m/%Y').date\n",
    "df_output['championship'] = future_matches['championship'].values\n",
    "\n",
    "columns=['Team 1', 'Team 2', 'Team 1 Win Odd', 'Draw Odd', 'Team 2 Win Odd',\n",
    "         'Team 1 -1.5 Odd', 'Team 1 +1.5 Odd', 'Team 2 -1.5 Odd', 'Team 2 +1.5 Odd',\n",
    "         'Team 1 -2.5 Odd', 'Team 1 +2.5 Odd', 'Team 2 -2.5 Odd', 'Team 2 +2.5 Odd',\n",
    "         'Team 1 Over 4.5', 'Team 1 Under 4.5', 'Team 2 Over 4.5', 'Team 2 Under 4.5']\n",
    "\n",
    "\n",
    "df_output = df_output.join(pd.DataFrame(output, columns=columns))\n",
    "\n",
    "df_output = df_output.sort_values(['championship', 'date'])\n",
    "\n",
    "df_output.to_excel(\"output_corners_AH.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
